"""
LLM ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
OpenAI GPT vs Google Vertex AI Gemini ì„±ëŠ¥ ë° ê²°ê³¼ í’ˆì§ˆ ë¹„êµ
"""

import os
import sys
import json
from datetime import datetime
from typing import List
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from langchain_google_vertexai import ChatVertexAI
from langchain.schema import HumanMessage
from src.models.multi_llm_analyzer import MultiLLMAnalyzer
from src.models.stt_llm_analysis import MeetingAnalyzer
from src.prompts.stt_llm_prompts import COMPREHENSIVE_MEETING_ANALYSIS_PROMPT
from src.config.config import (
    GOOGLE_CLOUD_PROJECT,
    GOOGLE_CLOUD_LOCATION,
    VERTEX_AI_MODEL,
    VERTEX_AI_TEMPERATURE,
    VERTEX_AI_MAX_TOKENS
)

def load_sample_transcript(file_path: str) -> dict:
    """ì‹¤ì œ ì „ì‚¬ íŒŒì¼ì—ì„œ STT ë°ì´í„° ë¡œë“œ"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        # íŒŒì¼ í˜•ì‹ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if file_path.endswith("test_1on1.txt"):
            selected_text = content.strip()
        elif "Geminiê°€ ì‘ì„±í•œ íšŒì˜ë¡.txt" in file_path:
            # Gemini íšŒì˜ë¡ íŒŒì¼ì€ ì „ì²´ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            selected_text = content.strip() 
        else:
            selected_text = _extract_transcript_text(content)
        
        return {
            "status": "success",
            "full_text": selected_text,
            "timestamp": "2025-07-28T16:44:07",
            # ë””ë²„ê¹…ìš© ì •ë³´
            "options": _get_debug_info(content)
        }
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def _extract_transcript_text(content: str) -> str:
    """ì „ì‚¬ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    full_transcript = _extract_full_text(content)
    speaker_separated = _extract_speaker_text(content)
    
    # í™”ìë³„ ë°œì–¸ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
    return speaker_separated.strip() if speaker_separated.strip() else full_transcript.strip()

def _extract_full_text(content: str) -> str:
    """ì „ì²´ í…ìŠ¤íŠ¸ ì„¹ì…˜ ì¶”ì¶œ"""
    lines = content.split('\n')
    full_transcript = ""
    in_full_text = False
    
    for line in lines:
        if "## ì „ì²´ í…ìŠ¤íŠ¸" in line:
            in_full_text = True
            continue
        elif "## í™”ìë³„ ë°œì–¸" in line:
            break
        elif in_full_text and line.strip() and not line.startswith("#"):
            full_transcript += line + " "
    
    return full_transcript

def _extract_speaker_text(content: str) -> str:
    """í™”ìë³„ ë°œì–¸ ì„¹ì…˜ ì¶”ì¶œ"""
    lines = content.split('\n')
    speaker_separated = ""
    in_speaker_section = False
    
    for line in lines:
        if "## í™”ìë³„ ë°œì–¸" in line:
            in_speaker_section = True
            continue
        elif in_speaker_section and line.strip():
            speaker_separated += line + "\n"
    
    return speaker_separated

def _get_debug_info(content: str) -> dict:
    """ë””ë²„ê¹… ì •ë³´ ìƒì„±"""
    full_transcript = _extract_full_text(content)
    speaker_separated = _extract_speaker_text(content)
    
    return {
        "full_transcript_length": len(full_transcript.strip()),
        "speaker_separated_length": len(speaker_separated.strip()), 
        "raw_content_length": len(content)
    }


def print_section(title: str, content: str):
    """ì„¹ì…˜ ì¶œë ¥ í•¨ìˆ˜"""
    print("\n" + "="*80)
    print(f" {title}")
    print("="*80)
    print(content)


def save_comparison_results(results: dict):
    """ë¹„êµ ê²°ê³¼ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # data ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs("data", exist_ok=True)
    
    model_comparison = results.get("model_comparison", {})
    
    # OpenAI ê²°ê³¼ íŒŒì¼ ì €ì¥
    if "openai_analysis" in model_comparison:
        openai_filename = f"openai_gpt_result_{timestamp}.md"
        openai_filepath = os.path.join("data", openai_filename)
        
        with open(openai_filepath, "w", encoding="utf-8") as f:
            f.write("# OpenAI GPT íšŒì˜ ë¶„ì„ ê²°ê³¼\n\n")
            f.write(f"ìƒì„± ì‹œê°„: {timestamp}\n\n")
            f.write("---\n\n")
            f.write(model_comparison["openai_analysis"])
        
        print(f"ğŸ’¾ OpenAI GPT ê²°ê³¼ ì €ì¥: {openai_filepath}")
    
    # Vertex AI ê²°ê³¼ íŒŒì¼ ì €ì¥
    if "vertexai_analysis" in model_comparison:
        vertexai_filename = f"vertexai_gemini_result_{timestamp}.md"
        vertexai_filepath = os.path.join("data", vertexai_filename)
        
        with open(vertexai_filepath, "w", encoding="utf-8") as f:
            f.write("# Google Vertex AI Gemini íšŒì˜ ë¶„ì„ ê²°ê³¼\n\n")
            f.write(f"ìƒì„± ì‹œê°„: {timestamp}\n\n")
            f.write("---\n\n")
            f.write(model_comparison["vertexai_analysis"])
        
        print(f"ğŸ’¾ Vertex AI Gemini ê²°ê³¼ ì €ì¥: {vertexai_filepath}")




def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ LLM í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ì„ íƒí•˜ì„¸ìš”:")
    print("1. LLM ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ (OpenAI vs Gemini)")
    print("2. í†µí•© 1on1 ë¶„ì„ í…ŒìŠ¤íŠ¸ (ìš”ì•½+í”¼ë“œë°±+Q&A)")
    
    choice = input("\nì„ íƒ (1 ë˜ëŠ” 2): ").strip()
    
    if choice == "1":
        _run_llm_comparison_test()
    elif choice == "2":
        _run_comprehensive_analysis_test()
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1 ë˜ëŠ” 2ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

def _run_llm_comparison_test():
    """LLM ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    transcript_file = "/Users/kimjoonhee/Documents/Orblit_1on1_AI/[ë¦¬ë²„ìŠ¤ë§ˆìš´í‹´] ì„œë¹„ìŠ¤ ê´€ë ¨ ë¯¸íŒ… - 2025_08_01 08_49 KST - Geminiê°€ ì‘ì„±í•œ íšŒì˜ë¡.txt"
    
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: OpenAI GPT vs Google Vertex AI Gemini")
    print(f"ğŸ“„ ì „ì‚¬ íŒŒì¼ ë¡œë“œ ì¤‘: {transcript_file}")
    
    stt_data = load_sample_transcript(transcript_file)
    if not stt_data:
        print("âŒ ì „ì‚¬ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ì „ì‚¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(stt_data['full_text'])}ì")
    
    # MultiLLMAnalyzer ì´ˆê¸°í™”
    print("\nğŸ”§ LLM ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    analyzer = MultiLLMAnalyzer()
    
    # STT ê²°ê³¼ë¥¼ ë‘ ëª¨ë¸ë¡œ ë¶„ì„
    print("\nğŸ”„ STT ê²°ê³¼ ë¶„ì„ ì¤‘...")
    comparison_results = analyzer.analyze_stt_with_comparison(stt_data)
    
    # ê²°ê³¼ ì¶œë ¥
    model_comparison = comparison_results.get("model_comparison", {})
    
    if "error" in model_comparison:
        print(f"âŒ ì˜¤ë¥˜: {model_comparison['error']}")
        return

    # ê²°ê³¼ ì €ì¥
    save_comparison_results(comparison_results)
    print("\nâœ… LLM ë¹„êµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

def _run_comprehensive_analysis_test():
    """í†µí•© 1on1 ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    transcript_file = "/Users/kimjoonhee/Documents/Orblit_1on1_AI/[ë¦¬ë²„ìŠ¤ë§ˆìš´í‹´] ì„œë¹„ìŠ¤ ê´€ë ¨ ë¯¸íŒ… - 2025_08_01 08_49 KST - Geminiê°€ ì‘ì„±í•œ íšŒì˜ë¡.txt"
    
    print("\nğŸ¯ í†µí•© 1on1 ë¶„ì„ í…ŒìŠ¤íŠ¸ (ìš”ì•½+í”¼ë“œë°±+Q&A)")
    print(f"ğŸ“„ ì „ì‚¬ íŒŒì¼: {transcript_file}")
    
    # ì „ì‚¬ íŒŒì¼ ë¡œë“œ
    stt_data = load_sample_transcript(transcript_file)
    if not stt_data:
        print("âŒ ì „ì‚¬ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    transcript = stt_data['full_text']
    print(f"âœ… ì „ì‚¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ (ê¸¸ì´: {len(transcript)}ì)")
    
    # MeetingAnalyzer ì´ˆê¸°í™”
    try:
        analyzer = MeetingAnalyzer()
        print("âœ… MeetingAnalyzer ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # í†µí•© ë¶„ì„ ì‹¤í–‰
    print("\nğŸ”„ í†µí•© 1on1 ë¶„ì„ ì¤‘...")
    try:
        comprehensive_result = analyzer.analyze_comprehensive(transcript)
        
        # ê²°ê³¼ ì¶œë ¥
        print_section("1on1 ì¢…í•© ë¶„ì„ ê²°ê³¼", comprehensive_result)
        
        # ê²°ê³¼ ì €ì¥
        save_comprehensive_result(comprehensive_result, len(transcript))
        
        print("\nâœ… í†µí•© 1on1 ë¶„ì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í†µí•© ë¶„ì„ ì‹¤íŒ¨: {e}")


def save_comprehensive_result(comprehensive_result: str, transcript_length: int):
    """í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # data ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs("data", exist_ok=True)
    
    # í†µí•© ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì €ì¥
    result_filename = f"comprehensive_analysis_{timestamp}.md"
    result_filepath = os.path.join("data", result_filename)
    
    with open(result_filepath, "w", encoding="utf-8") as f:
        f.write("# 1on1 ì¢…í•© ë¶„ì„ ê²°ê³¼\n\n")
        f.write(f"ìƒì„± ì‹œê°„: {timestamp}\n")
        f.write(f"ì „ì‚¬ ë‚´ìš© ê¸¸ì´: {transcript_length}ì\n\n")
        f.write("---\n\n")
        f.write(comprehensive_result)
        f.write(f"\n\n---\n\n")
        f.write("## ë¶„ì„ ì •ë³´\n")
        f.write(f"- ë¶„ì„ ì‹œê°„: {timestamp}\n")
        f.write(f"- ì‚¬ìš© í”„ë¡¬í”„íŠ¸: COMPREHENSIVE_MEETING_ANALYSIS_PROMPT\n")
        f.write(f"- í¬í•¨ ê¸°ëŠ¥: íšŒì˜ ìš”ì•½ + ë§¤ë‹ˆì € í”¼ë“œë°± + Q&A ë‹µë³€\n")
    
    print(f"ğŸ’¾ í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥: {result_filepath}")
    


if __name__ == "__main__":
    main()