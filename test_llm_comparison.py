"""
LLM ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
OpenAI GPT vs Google Vertex AI Gemini ì„±ëŠ¥ ë° ê²°ê³¼ í’ˆì§ˆ ë¹„êµ
"""

import os
import json
from datetime import datetime
from src.models.multi_llm_analyzer import MultiLLMAnalyzer

def load_sample_transcript(file_path: str) -> dict:
    """ì‹¤ì œ ì „ì‚¬ íŒŒì¼ì—ì„œ STT ë°ì´í„° ë¡œë“œ"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        # 3ê°€ì§€ í˜•íƒœë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        lines = content.split('\n')
        
        # 1. ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸ (ê¸°ì¡´)
        full_transcript = ""
        in_full_text = False
        
        # 2. í™”ìë³„ ë°œì–¸ë§Œ (í™”ì ì •ë³´ í¬í•¨)
        speaker_separated = ""
        in_speaker_section = False
        
        # 3. ì „ì²´ íŒŒì¼ ë‚´ìš© (ì›ë³¸ ê·¸ëŒ€ë¡œ)
        raw_content = content
        
        for line in lines:
            # ì „ì²´ í…ìŠ¤íŠ¸ ì„¹ì…˜ íŒŒì‹±
            if "## ì „ì²´ í…ìŠ¤íŠ¸" in line:
                in_full_text = True
                continue
            elif "## í™”ìë³„ ë°œì–¸" in line:
                in_full_text = False
                in_speaker_section = True
                continue
            elif in_full_text and line.strip() and not line.startswith("#"):
                full_transcript += line + " "
            
            # í™”ìë³„ ë°œì–¸ ì„¹ì…˜ íŒŒì‹±
            elif in_speaker_section and line.strip():
                speaker_separated += line + "\n"
        
        # ì„ íƒí•  ìˆ˜ ìˆëŠ” 3ê°€ì§€ ì˜µì…˜ (ì—¬ê¸°ì„œ ë³€ê²½í•˜ì—¬ ì›í•˜ëŠ” í˜•íƒœ ì„ íƒ)
        # Option 1: ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸ë§Œ
        # Option 2: í™”ì ë¶„ë¦¬ëœ ë‚´ìš©ë§Œ  
        # Option 3: ì „ì²´ íŒŒì¼ ë‚´ìš©
        
        selected_text = full_transcript.strip()  # ğŸ”„ ì—¬ê¸°ì„œ ë³€ê²½: full_transcript, speaker_separated, raw_content ì¤‘ ì„ íƒ
        
        return {
            "status": "success",
            "full_text": selected_text,
            "timestamp": "2025-07-28T16:44:07",
            # ë””ë²„ê¹…ìš© ì •ë³´
            "options": {
                "full_transcript_length": len(full_transcript.strip()),
                "speaker_separated_length": len(speaker_separated.strip()), 
                "raw_content_length": len(raw_content)
            }
        }
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None


def print_section(title: str, content: str):
    """ì„¹ì…˜ ì¶œë ¥ í•¨ìˆ˜"""
    print("\n" + "="*80)
    print(f" {title}")
    print("="*80)
    print(content)


def save_comparison_results(results: dict):
    """ë¹„êµ ê²°ê³¼ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # data ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs("data", exist_ok=True)
    
    model_comparison = results.get("model_comparison", {})
    
    # OpenAI ê²°ê³¼ íŒŒì¼ ì €ì¥
    if "openai_analysis" in model_comparison:
        openai_filename = f"openai_gpt_result_{timestamp}.md"
        openai_filepath = os.path.join("data", openai_filename)
        
        with open(openai_filepath, "w", encoding="utf-8") as f:
            f.write("# OpenAI GPT íšŒì˜ ë¶„ì„ ê²°ê³¼\n\n")
            f.write(f"ìƒì„± ì‹œê°„: {timestamp}\n\n")
            f.write("---\n\n")
            f.write(model_comparison["openai_analysis"])
        
        print(f"ğŸ’¾ OpenAI GPT ê²°ê³¼ ì €ì¥: {openai_filepath}")
    
    # Vertex AI ê²°ê³¼ íŒŒì¼ ì €ì¥
    if "vertexai_analysis" in model_comparison:
        vertexai_filename = f"vertexai_gemini_result_{timestamp}.md"
        vertexai_filepath = os.path.join("data", vertexai_filename)
        
        with open(vertexai_filepath, "w", encoding="utf-8") as f:
            f.write("# Google Vertex AI Gemini íšŒì˜ ë¶„ì„ ê²°ê³¼\n\n")
            f.write(f"ìƒì„± ì‹œê°„: {timestamp}\n\n")
            f.write("---\n\n")
            f.write(model_comparison["vertexai_analysis"])
        
        print(f"ğŸ’¾ Vertex AI Gemini ê²°ê³¼ ì €ì¥: {vertexai_filepath}")
    
def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ LLM ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: OpenAI GPT vs Google Vertex AI Gemini")
    
    # ì‹¤ì œ ì „ì‚¬ íŒŒì¼ ë¡œë“œ
    transcript_file = "/Users/kimjoonhee/Documents/Orblit_1on1_AI/transcription_20250801_165627.txt"
    
    print(f"ğŸ“„ ì „ì‚¬ íŒŒì¼ ë¡œë“œ ì¤‘: {transcript_file}")
    stt_data = load_sample_transcript(transcript_file)
    
    if not stt_data:
        print("âŒ ì „ì‚¬ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ì „ì‚¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   - ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(stt_data['full_text'])}ì")
    
    # MultiLLMAnalyzer ì´ˆê¸°í™”
    print("\nğŸ”§ LLM ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    analyzer = MultiLLMAnalyzer()
    
    # STT ê²°ê³¼ë¥¼ ë‘ ëª¨ë¸ë¡œ ë¶„ì„
    print("\nğŸ”„ STT ê²°ê³¼ ë¶„ì„ ì¤‘...")
    comparison_results = analyzer.analyze_stt_with_comparison(stt_data)
    
    # ê²°ê³¼ ì¶œë ¥
    model_comparison = comparison_results.get("model_comparison", {})
    
    if "error" in model_comparison:
        print(f"âŒ ì˜¤ë¥˜: {model_comparison['error']}")
        return

    # ê²°ê³¼ ì €ì¥
    save_comparison_results(comparison_results)
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    


if __name__ == "__main__":
    main()