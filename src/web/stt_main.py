from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional
import logging

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from src.config.config import (
    ASSEMBLYAI_API_KEY,
    GOOGLE_CLOUD_PROJECT, 
    GOOGLE_CLOUD_LOCATION,
    GOOGLE_APPLICATION_CREDENTIALS_JSON,
    SUPABASE_URL,
    SUPABASE_KEY,
    SUPABASE_BUCKET_NAME
)
import os
import json
from datetime import datetime
from fastapi.responses import JSONResponse
import assemblyai as aai
from supabase import create_client, Client

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("stt_main")

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
meeting_analyzer = None
meeting_pipeline = None
supabase: Client = None

# ë” ì´ìƒ Pydantic ëª¨ë¸ì´ í•„ìš”í•˜ì§€ ì•ŠìŒ (Form ë°ì´í„° ì§ì ‘ ì²˜ë¦¬)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    global meeting_analyzer, meeting_pipeline, supabase
    
    # Google ìê²©ì¦ëª… ì„¤ì •
    if GOOGLE_APPLICATION_CREDENTIALS_JSON:
        creds_path = "/tmp/gcp_creds.json"
        with open(creds_path, "w", encoding="utf-8") as f:
            f.write(GOOGLE_APPLICATION_CREDENTIALS_JSON)
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = creds_path
    
    # Supabase ì´ˆê¸°í™”
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # AssemblyAI ì´ˆê¸°í™”
    aai.settings.api_key = ASSEMBLYAI_API_KEY
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    from src.utils.model import MeetingAnalyzer
    from src.services.meeting_analyze.meeting_pipeline import MeetingPipeline
    
    meeting_analyzer = MeetingAnalyzer(
        google_project=GOOGLE_CLOUD_PROJECT, 
        google_location=GOOGLE_CLOUD_LOCATION
    )
    
    # LangGraph íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    meeting_pipeline = MeetingPipeline(
        supabase_client=supabase,
        analyzer=meeting_analyzer
    )
    
    logger.info("ëª¨ë“  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    logger.info(f"Supabase ì—°ê²°: {SUPABASE_URL}")
    logger.info(f"ê¸°ë³¸ ë²„í‚·: {SUPABASE_BUCKET_NAME}")
    logger.info("LangGraph íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    yield
    # ì¢…ë£Œì‹œ ì •ë¦¬ (í•„ìš”ì‹œ)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="1on1 Meeting AI Analysis", 
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """ë©”ì¸ í˜ì´ì§€"""
    from fastapi.responses import FileResponse
    return FileResponse("frontend/index.html")

@app.get("/api.js")
async def api_js():
    """API JavaScript íŒŒì¼"""
    from fastapi.responses import FileResponse
    return FileResponse("frontend/api.js", media_type="application/javascript")

@app.get("/app.js")
async def app_js():
    """ì•± JavaScript íŒŒì¼"""
    from fastapi.responses import FileResponse
    return FileResponse("frontend/app.js", media_type="application/javascript")


@app.get("/api/config")
async def get_config():
    """í”„ë¡ íŠ¸ì—”ë“œìš© ì„¤ì • ì •ë³´ ì œê³µ"""
    return {
        "supabase_url": SUPABASE_URL,
        "supabase_key": SUPABASE_KEY,
        "bucket_name": SUPABASE_BUCKET_NAME
    }


@app.post("/api/record-and-analyze")
async def record_and_analyze_meeting(
    audio_file: bytes = Form(...),
    filename: str = Form(...),
    qa_data: Optional[str] = Form(default=None),
    participants_info: Optional[str] = Form(default=None),
    meeting_datetime: Optional[str] = Form(default=None),
    bucket_name: Optional[str] = Form(default=SUPABASE_BUCKET_NAME)
):
    """
    ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  Supabaseì— ì €ì¥í•œ í›„ 1on1 ë¯¸íŒ… ë¶„ì„ ìˆ˜í–‰
    
    Args:
        audio_file: ì—…ë¡œë“œëœ ìŒì„± íŒŒì¼ (ë°”ì´íŠ¸)
        filename: íŒŒì¼ëª…
        qa_data: Q&A ë°ì´í„° (JSON ë¬¸ìì—´)
        participants_info: ì°¸ê°€ì ì •ë³´ (JSON ë¬¸ìì—´)
        bucket_name: ë²„í‚· ì´ë¦„
    """
    if not meeting_pipeline:
        raise HTTPException(status_code=503, detail="íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        logger.info(f"ğŸ¤ ìŒì„± íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„ ì‹œì‘: {filename}")
        
        # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_extension = filename.split('.')[-1] if '.' in filename else 'wav'
        unique_filename = f"{timestamp}_{filename}"
        
        # Supabaseì— íŒŒì¼ ì—…ë¡œë“œ
        upload_result = supabase.storage.from_(bucket_name).upload(
            path=unique_filename,
            file=audio_file,
            file_options={"content-type": f"audio/{file_extension}"}
        )
        
        if hasattr(upload_result, 'error') and upload_result.error:
            raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_result.error}")
        
        logger.info(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {unique_filename}")
        
        # JSON ì…ë ¥ íŒŒì‹±
        qa_list = json.loads(qa_data) if qa_data else None
        participants = json.loads(participants_info) if participants_info else None
        
        # LangGraph íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = await meeting_pipeline.run(
            file_id=unique_filename,
            bucket_name=bucket_name,
            qa_data=qa_list,
            participants_info=participants,
            meeting_datetime=meeting_datetime
        )
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨ ì²˜ë¦¬
        if result["status"] == "failed":
            error_details = "; ".join(result.get("errors", ["ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"]))
            raise HTTPException(status_code=500, detail=f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {error_details}")
        
        # ì„±ê³µ ì‘ë‹µ ìƒì„±
        analysis_data = result.get("analysis_result", {})
        transcript_data = result.get("transcript", {})
        speaker_stats_percent = result.get("speaker_stats_percent", {})
        formatted_transcript = result.get("formatted_transcript", transcript_data.get("utterances", []))
        
        response = {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            **analysis_data,
            "transcript": {
                "utterances": formatted_transcript
            },
            "speaker_stats_percent": speaker_stats_percent,
            "file_info": {
                "file_id": unique_filename,
                "bucket_name": bucket_name,
                "file_path": result.get("file_path", ""),
                "uploaded_filename": filename
            },
            "pipeline_info": {
                "pipeline_status": result["status"],
                "errors": result.get("errors", [])
            }
        }
        
        logger.info(f"âœ… ìŒì„± íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„ ì™„ë£Œ: {unique_filename}")
        return JSONResponse(content=response)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìŒì„± íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.post("/api/analyze")
async def analyze_meeting_with_storage(
    file_id: str = Form(...),
    qa_data: Optional[str] = Form(default=None),
    participants_info: Optional[str] = Form(default=None),
    meeting_datetime: Optional[str] = Form(default=None),
    bucket_name: Optional[str] = Form(default=SUPABASE_BUCKET_NAME)
):
    """
    LangGraph íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•œ 1on1 ë¯¸íŒ… ë¶„ì„ API
    
    Args:
        file_id: Supabase ìŠ¤í† ë¦¬ì§€ íŒŒì¼ ID
        qa_data: Q&A ë°ì´í„° (JSON ë¬¸ìì—´)
        participants_info: ì°¸ê°€ì ì •ë³´ (JSON ë¬¸ìì—´)
        bucket_name: ë²„í‚· ì´ë¦„
    """
    if not meeting_pipeline:
        raise HTTPException(status_code=503, detail="íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        logger.info(f"ğŸš€ LangGraph íŒŒì´í”„ë¼ì¸ ì‹œì‘: {file_id}")
        
        # JSON ì…ë ¥ íŒŒì‹±
        qa_list = json.loads(qa_data) if qa_data else None
        participants = json.loads(participants_info) if participants_info else None
        
        # LangGraph íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = await meeting_pipeline.run(
            file_id=file_id,
            bucket_name=bucket_name,
            qa_data=qa_list,
            participants_info=participants,
            meeting_datetime=meeting_datetime
        )
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨ ì²˜ë¦¬
        if result["status"] == "failed":
            error_details = "; ".join(result.get("errors", ["ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"]))
            raise HTTPException(status_code=500, detail=f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {error_details}")
        
        # ì„±ê³µ ì‘ë‹µ ìƒì„±
        analysis_data = result.get("analysis_result", {})
        transcript_data = result.get("transcript", {})
        speaker_stats_percent = result.get("speaker_stats_percent", {})
        formatted_transcript = result.get("formatted_transcript", transcript_data.get("utterances", []))
        
        response = {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            **analysis_data,
            "transcript": {
                "utterances": formatted_transcript
            },
            "speaker_stats_percent": speaker_stats_percent,
            "file_info": {
                "file_id": file_id,
                "bucket_name": bucket_name,
                "file_path": result.get("file_path", "")
            },
            "pipeline_info": {
                "pipeline_status": result["status"],
                "errors": result.get("errors", [])
            }
        }
        
        logger.info(f"âœ… LangGraph íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {file_id}")
        return JSONResponse(content=response)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)