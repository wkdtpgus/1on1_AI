"""
ë‹¤ì¤‘ LLM ëª¨ë¸ì„ ì‚¬ìš©í•œ STT ë¶„ì„ ë¹„êµ ëª¨ë“ˆ
OpenAI GPTì™€ Google Vertex AI Gemini ëª¨ë¸ ë¹„êµ
"""

import json
import time
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_google_vertexai import ChatVertexAI
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field

# ì„¤ì • ê°€ì ¸ì˜¤ê¸°
from src.config.config import (
    OPENAI_API_KEY,
    LLM_MODEL,
    LLM_TEMPERATURE,
    LLM_MAX_TOKENS,
    GOOGLE_CLOUD_PROJECT,
    GOOGLE_CLOUD_LOCATION,
    VERTEX_AI_MODEL,
    VERTEX_AI_TEMPERATURE,
    VERTEX_AI_MAX_TOKENS
)
from src.prompts.stt_llm_prompts import COMPREHENSIVE_MEETING_ANALYSIS_PROMPT


class ModelComparisonResult(BaseModel):
    """ëª¨ë¸ ë¹„êµ ê²°ê³¼"""
    openai_result: str = Field(description="OpenAI GPT ê²°ê³¼")
    vertexai_result: str = Field(description="Vertex AI Gemini ê²°ê³¼")
    openai_response_time: float = Field(description="OpenAI ì‘ë‹µ ì‹œê°„(ì´ˆ)")
    vertexai_response_time: float = Field(description="Vertex AI ì‘ë‹µ ì‹œê°„(ì´ˆ)")
    comparison_notes: str = Field(description="ë¹„êµ ë©”ëª¨")


class MultiLLMAnalyzer:
    """ë‹¤ì¤‘ LLM ëª¨ë¸ì„ ì‚¬ìš©í•œ STT ë¶„ì„ ë¹„êµ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 openai_api_key: Optional[str] = None,
                 google_project: Optional[str] = None,
                 google_location: Optional[str] = None):
        """
        MultiLLMAnalyzer ì´ˆê¸°í™”
        
        Args:
            openai_api_key: OpenAI API í‚¤
            google_project: Google Cloud í”„ë¡œì íŠ¸ ID
            google_location: Google Cloud ë¦¬ì „
        """
        self.openai_api_key = openai_api_key or OPENAI_API_KEY
        self.google_project = google_project or GOOGLE_CLOUD_PROJECT
        self.google_location = google_location or GOOGLE_CLOUD_LOCATION
        
        # OpenAI LLM ì´ˆê¸°í™”
        self.openai_llm = None
        if self.openai_api_key:
            try:
                self.openai_llm = ChatOpenAI(
                    openai_api_key=self.openai_api_key,
                    model=LLM_MODEL,
                    temperature=LLM_TEMPERATURE,
                    max_tokens=LLM_MAX_TOKENS
                )
                print(f"âœ… OpenAI {LLM_MODEL} ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ OpenAI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Vertex AI LLM ì´ˆê¸°í™”
        self.vertexai_llm = None
        if self.google_project:
            try:
                self.vertexai_llm = ChatVertexAI(
                    project=self.google_project,
                    location=self.google_location,
                    model_name=VERTEX_AI_MODEL,
                    temperature=VERTEX_AI_TEMPERATURE,
                    max_output_tokens=VERTEX_AI_MAX_TOKENS
                )
                print(f"âœ… Vertex AI {VERTEX_AI_MODEL} ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ Vertex AI ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        self.prompt_template = PromptTemplate(
            input_variables=["transcript"],
            template=COMPREHENSIVE_MEETING_ANALYSIS_PROMPT
        )
    
    def analyze_with_openai(self, transcript: str) -> tuple[str, float]:
        """OpenAI GPT ëª¨ë¸ë¡œ ë¶„ì„"""
        if not self.openai_llm:
            return "OpenAI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", 0.0
        
        try:
            start_time = time.time()
            prompt = self.prompt_template.format(transcript=transcript)
            response = self.openai_llm.invoke(prompt)
            response_time = time.time() - start_time
            
            return response.content.strip(), response_time
            
        except Exception as e:
            return f"OpenAI ë¶„ì„ ì˜¤ë¥˜: {str(e)}", 0.0
    
    def analyze_with_vertexai(self, transcript: str) -> tuple[str, float]:
        """Vertex AI Gemini ëª¨ë¸ë¡œ ë¶„ì„"""
        if not self.vertexai_llm:
            return "Vertex AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", 0.0
        
        try:
            start_time = time.time()
            prompt = self.prompt_template.format(transcript=transcript)
            response = self.vertexai_llm.invoke(prompt)
            response_time = time.time() - start_time
            
            return response.content.strip(), response_time
            
        except Exception as e:
            return f"Vertex AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}", 0.0
    
    def compare_models(self, transcript: str) -> ModelComparisonResult:
        """ë‘ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë¹„êµ"""
        print("ğŸ”„ OpenAI GPT ëª¨ë¸ë¡œ ë¶„ì„ ì¤‘...")
        openai_result, openai_time = self.analyze_with_openai(transcript)
        
        print("ğŸ”„ Vertex AI Gemini ëª¨ë¸ë¡œ ë¶„ì„ ì¤‘...")
        vertexai_result, vertexai_time = self.analyze_with_vertexai(transcript)
        
        # ë¹„êµ ë©”ëª¨ ìƒì„±
        comparison_notes = f"""
ëª¨ë¸ ë¹„êµ ê²°ê³¼:
- OpenAI ì‘ë‹µ ì‹œê°„: {openai_time:.2f}ì´ˆ
- Vertex AI ì‘ë‹µ ì‹œê°„: {vertexai_time:.2f}ì´ˆ
- ë¹ ë¥¸ ëª¨ë¸: {'OpenAI' if openai_time < vertexai_time else 'Vertex AI'}
        """.strip()
        
        return ModelComparisonResult(
            openai_result=openai_result,
            vertexai_result=vertexai_result,
            openai_response_time=openai_time,
            vertexai_response_time=vertexai_time,
            comparison_notes=comparison_notes
        )
    
    def analyze_stt_with_comparison(self, stt_result: Dict[str, Any]) -> Dict[str, Any]:
        """STT ê²°ê³¼ë¥¼ ë‘ ëª¨ë¸ë¡œ ë¶„ì„í•˜ê³  ë¹„êµ"""
        # ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
        full_transcript = stt_result.get("full_text", "")
        
        if not full_transcript:
            return {
                **stt_result,
                "model_comparison": {
                    "error": "ë¶„ì„í•  ì „ì‚¬ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
                }
            }
        
        # ë‘ ëª¨ë¸ë¡œ ë¶„ì„
        comparison_result = self.compare_models(full_transcript)
        
        return {
            **stt_result,
            "model_comparison": {
                "openai_analysis": comparison_result.openai_result,
                "vertexai_analysis": comparison_result.vertexai_result,
                "performance": {
                    "openai_response_time": comparison_result.openai_response_time,
                    "vertexai_response_time": comparison_result.vertexai_response_time
                },
                "comparison_notes": comparison_result.comparison_notes
            }
        }