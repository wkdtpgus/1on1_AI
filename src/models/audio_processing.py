"""
ì˜¤ë””ì˜¤ ë…¹ìŒ ë° ì „ì‚¬ í†µí•© ëª¨ë“ˆ
AudioRecorder: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë…¹ìŒ
STTProcessor: AssemblyAIë¥¼ ì‚¬ìš©í•œ Speech-to-Text ì²˜ë¦¬
"""

import assemblyai as aai
import os
import threading
import queue
import time
import json
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any
import numpy as np
import sounddevice as sd
import soundfile as sf

# Import config settings
from src.config.config import (
    # ì˜¤ë””ì˜¤ ê´€ë ¨ ì„¤ì •
    AUDIO_SAMPLE_RATE,
    AUDIO_CHANNELS,
    AUDIO_CHUNK_SIZE,
    AUDIO_FORMAT,
    TEMP_AUDIO_DIR,
    OUTPUT_DIR,
    # AssemblyAI ì„¤ì •
    ASSEMBLYAI_API_KEY,
    ASSEMBLYAI_SPEECH_MODEL,
    ASSEMBLYAI_LANGUAGE,
    ASSEMBLYAI_PUNCTUATE,
    ASSEMBLYAI_FORMAT_TEXT,
    ASSEMBLYAI_DISFLUENCIES,
    ASSEMBLYAI_SPEAKER_LABELS,
    ASSEMBLYAI_LANGUAGE_DETECTION,
    ASSEMBLYAI_WORD_BOOST,
    ASSEMBLYAI_BOOST_PARAM,
    ASSEMBLYAI_SPEAKERS_EXPECTED
)


class AudioRecorder:
    """ì˜¤ë””ì˜¤ ë…¹ìŒì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.sample_rate = AUDIO_SAMPLE_RATE
        self.channels = AUDIO_CHANNELS
        self.chunk_size = AUDIO_CHUNK_SIZE
        self.is_recording = False
        self.audio_queue = queue.Queue()
        self.recorded_frames = []
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        Path(TEMP_AUDIO_DIR).mkdir(parents=True, exist_ok=True)
        Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
        
    def _audio_callback(self, indata, frames, time_info, status):
        """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì½œë°± í•¨ìˆ˜"""
        if self.is_recording:
            self.audio_queue.put(indata.copy())
    
    def start_recording(self) -> bool:
        """ë…¹ìŒ ì‹œì‘"""
        try:
            self.is_recording = True
            self.recorded_frames = []
            self.audio_queue = queue.Queue()
            
            # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            self.stream = sd.InputStream(
                callback=self._audio_callback,
                channels=self.channels,
                samplerate=self.sample_rate,
                blocksize=self.chunk_size,
                dtype=AUDIO_FORMAT
            )
            self.stream.start()
            
            # ë…¹ìŒ ìŠ¤ë ˆë“œ ì‹œì‘
            self.recording_thread = threading.Thread(target=self._recording_worker)
            self.recording_thread.start()
            
            return True
            
        except Exception as e:
            print(f"ERROR: Failed to start recording: {str(e)}")
            self.is_recording = False
            return False
    
    def _recording_worker(self):
        """ë…¹ìŒ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.is_recording:
            try:
                # íƒ€ì„ì•„ì›ƒìœ¼ë¡œ íì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                audio_chunk = self.audio_queue.get(timeout=0.1)
                self.recorded_frames.append(audio_chunk)
            except queue.Empty:
                continue
    
    def stop_recording(self) -> Optional[str]:
        """ë…¹ìŒ ì¤‘ì§€ ë° íŒŒì¼ ì €ì¥"""
        if not self.is_recording:
            return None
            
        self.is_recording = False
        
        # ìŠ¤íŠ¸ë¦¼ ì •ì§€
        if hasattr(self, 'stream'):
            self.stream.stop()
            self.stream.close()
        
        # ë…¹ìŒ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if hasattr(self, 'recording_thread'):
            self.recording_thread.join(timeout=2.0)
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not self.recorded_frames:
            return None
        
        # ì˜¤ë””ì˜¤ ë°ì´í„° ê²°í•©
        audio_data = np.concatenate(self.recorded_frames, axis=0)
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"recording_{timestamp}.wav"
        filepath = os.path.join(TEMP_AUDIO_DIR, filename)
        
        try:
            sf.write(filepath, audio_data, self.sample_rate)
            return filepath
        except Exception as e:
            print(f"ERROR: Failed to save recording file: {str(e)}")
            return None


class STTProcessor:
    """AssemblyAIë¥¼ ì‚¬ìš©í•œ Speech-to-Text ì²˜ë¦¬ ë° JSON êµ¬ì¡°í™” í´ë˜ìŠ¤"""

    def __init__(self, api_key: Optional[str] = None):
        # API í‚¤ ì„¤ì •
        self.api_key = api_key or ASSEMBLYAI_API_KEY or os.getenv("ASSEMBLYAI_API_KEY")
        if not self.api_key:
            raise ValueError("AssemblyAI API key is required")
        
        # AssemblyAI ì„¤ì •
        aai.settings.api_key = self.api_key

    def transcribe_audio(self, audio_file: str, participants_info: Optional[Dict[str, Dict[str, str]]] = None) -> Dict[str, Any]:
        """
        AssemblyAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ ,
        ì§€ì •ëœ JSON êµ¬ì¡°ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
        
        :param audio_file: ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        :param participants_info: í™”ì ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: {"A": {"name": "ê¹€ì¤€í¬", "role": "íŒ€ì›"}})
        :return: êµ¬ì¡°í™”ëœ ì „ì‚¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not os.path.exists(audio_file):
            return {
                "status": "error",
                "message": f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}",
                "timestamp": datetime.now().isoformat()
            }

        try:
            config = aai.TranscriptionConfig(
                speech_model=getattr(aai.SpeechModel, ASSEMBLYAI_SPEECH_MODEL, aai.SpeechModel.best),
                language_code=ASSEMBLYAI_LANGUAGE,
                punctuate=ASSEMBLYAI_PUNCTUATE,
                format_text=ASSEMBLYAI_FORMAT_TEXT,
                disfluencies=ASSEMBLYAI_DISFLUENCIES,
                speaker_labels=ASSEMBLYAI_SPEAKER_LABELS,
                language_detection=ASSEMBLYAI_LANGUAGE_DETECTION,
                speakers_expected=ASSEMBLYAI_SPEAKERS_EXPECTED
            )

            if ASSEMBLYAI_WORD_BOOST:
                config.word_boost = ASSEMBLYAI_WORD_BOOST
                config.boost_param = ASSEMBLYAI_BOOST_PARAM

            transcriber = aai.Transcriber(config=config)
            transcript = transcriber.transcribe(audio_file)

            # ì „ì‚¬ ìƒíƒœ í™•ì¸ (ê¸°ë‹¤ë¦¬ëŠ” ë¡œì§ ì¶”ê°€)
            while transcript.status not in [aai.TranscriptStatus.completed, aai.TranscriptStatus.error]:
                time.sleep(5)
                transcript = transcript.get()

            if transcript.status == aai.TranscriptStatus.error:
                return {
                    "status": "error",
                    "message": f"ì „ì‚¬ ì‹¤íŒ¨: {transcript.error}",
                    "audio_file": audio_file,
                    "timestamp": datetime.now().isoformat()
                }

            # ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ JSON êµ¬ì¡°ë¡œ í¬ë§·íŒ…
            formatted_result = self._format_transcription_result(transcript, audio_file, participants_info)

            # ê²°ê³¼ ì €ì¥
            self._save_transcription_result(formatted_result)

            return formatted_result

        except Exception as e:
            print(f"âŒ ì „ì‚¬ ì˜¤ë¥˜: {e}")
            return {
                "status": "error",
                "message": f"ì „ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "audio_file": audio_file,
                "timestamp": datetime.now().isoformat()
            }

    def _format_transcription_result(self, transcript: aai.Transcript, audio_file: str, participants_info: Optional[Dict[str, Dict[str, str]]]) -> Dict[str, Any]:
        """AssemblyAI ì „ì‚¬ ê²°ê³¼ë¥¼ ê°„ë‹¨í•œ í™”ìë³„ ë°œì–¸ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        
        if not hasattr(transcript, 'utterances') or not transcript.utterances:
            return {
                "transcript": "ì „ì‚¬ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.",
                "status": "success_but_no_utterances",
                "timestamp": datetime.now().isoformat()
            }

        # í™”ì ë§¤í•‘ ìƒì„± (A, B, C... ë˜ëŠ” ì‹¤ì œ ì´ë¦„ ì‚¬ìš©)
        unique_labels = sorted(list(set(u.speaker for u in transcript.utterances)))
        speaker_mapping = {}
        
        for i, label in enumerate(unique_labels):
            # participants_infoê°€ ìˆìœ¼ë©´ ì‹¤ì œ ì´ë¦„ ì‚¬ìš©, ì—†ìœ¼ë©´ A, B, C...
            if participants_info and label in participants_info:
                speaker_name = participants_info[label]["name"]
            else:
                speaker_name = chr(65 + i)  # A, B, C...
            speaker_mapping[label] = speaker_name

        # í™”ìë³„ ë°œì–¸ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì¡°í•©
        transcript_lines = []
        for utterance in transcript.utterances:
            speaker_name = speaker_mapping.get(utterance.speaker, "ì°¸ì„ì")
            transcript_lines.append(f"{speaker_name}: {utterance.text}")

        return {
            "transcript": "\n".join(transcript_lines),
            "status": "success",
            "timestamp": datetime.now().isoformat()
        }

    def _save_transcription_result(self, result: Dict[str, Any]):
        """ê°„ì†Œí™”ëœ ì „ì‚¬ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # JSON íŒŒì¼ ì €ì¥ (ê°„ë‹¨í•œ í˜•ì‹)
            json_file_path = os.path.join(OUTPUT_DIR, f"transcript_{timestamp}.json")
            with open(json_file_path, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ì „ì‚¬ ê²°ê³¼ ì €ì¥: {json_file_path}")

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")


class AudioProcessor:
    """ì˜¤ë””ì˜¤ ë…¹ìŒê³¼ ì „ì‚¬ë¥¼ í†µí•© ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, assemblyai_api_key: Optional[str] = None):
        """
        AudioProcessor ì´ˆê¸°í™”
        
        Args:
            assemblyai_api_key: AssemblyAI API í‚¤
        """
        self.recorder = AudioRecorder()
        self.stt_processor = STTProcessor(api_key=assemblyai_api_key)
    
    def start_recording(self) -> bool:
        """ë…¹ìŒ ì‹œì‘"""
        return self.recorder.start_recording()
    
    def stop_recording_and_transcribe(self, participants_info: Optional[Dict[str, Dict[str, str]]] = None) -> Dict[str, Any]:
        """
        ë…¹ìŒ ì¤‘ì§€í•˜ê³  ì „ì‚¬ ìˆ˜í–‰
        
        Args:
            participants_info: í™”ì ì •ë³´
            
        Returns:
            ì „ì‚¬ ê²°ê³¼
        """
        # ë…¹ìŒ ì¤‘ì§€í•˜ê³  íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        audio_file = self.recorder.stop_recording()
        
        if not audio_file:
            return {
                "status": "error",
                "message": "ë…¹ìŒëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.",
                "timestamp": datetime.now().isoformat()
            }
        
        print(f"ğŸµ ë…¹ìŒ ì™„ë£Œ: {audio_file}")
        
        # ì „ì‚¬ ìˆ˜í–‰
        print("ğŸ“ ì „ì‚¬ ì‹œì‘...")
        transcription_result = self.stt_processor.transcribe_audio(audio_file, participants_info)
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì„ íƒì )
        try:
            os.remove(audio_file)
            print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬: {audio_file}")
        except Exception as e:
            print(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        return transcription_result
    
    def transcribe_existing_file(self, audio_file: str, participants_info: Optional[Dict[str, Dict[str, str]]] = None) -> Dict[str, Any]:
        """
        ê¸°ì¡´ ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬
        
        Args:
            audio_file: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            participants_info: í™”ì ì •ë³´
            
        Returns:
            ì „ì‚¬ ê²°ê³¼
        """
        return self.stt_processor.transcribe_audio(audio_file, participants_info)