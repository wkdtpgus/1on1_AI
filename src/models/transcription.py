import assemblyai as aai
import os
import time
import threading
import queue
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any
import numpy as np
import sounddevice as sd
import soundfile as sf
import assemblyai as aai

# Import config settings
from src.config.config import (
    ASSEMBLYAI_API_KEY,
    ASSEMBLYAI_SPEECH_MODEL,
    ASSEMBLYAI_LANGUAGE,
    ASSEMBLYAI_PUNCTUATE,
    ASSEMBLYAI_FORMAT_TEXT,
    ASSEMBLYAI_DISFLUENCIES,
    ASSEMBLYAI_SPEAKER_LABELS,
    ASSEMBLYAI_LANGUAGE_DETECTION,
    ASSEMBLYAI_WORD_BOOST,
    ASSEMBLYAI_BOOST_PARAM,
    ASSEMBLYAI_SPEAKERS_EXPECTED,
    AUDIO_SAMPLE_RATE,
    AUDIO_CHANNELS,
    AUDIO_CHUNK_SIZE,
    AUDIO_FORMAT,
    TEMP_AUDIO_DIR,
    OUTPUT_DIR
)


class AudioRecorder:
    """ì˜¤ë””ì˜¤ ë…¹ìŒì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.sample_rate = AUDIO_SAMPLE_RATE
        self.channels = AUDIO_CHANNELS
        self.chunk_size = AUDIO_CHUNK_SIZE
        self.is_recording = False
        self.audio_queue = queue.Queue()
        self.recorded_frames = []
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        Path(TEMP_AUDIO_DIR).mkdir(parents=True, exist_ok=True)
        Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
        
    def _audio_callback(self, indata, frames, time_info, status):
        """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì½œë°± í•¨ìˆ˜"""
        if self.is_recording:
            self.audio_queue.put(indata.copy())
    
    def start_recording(self) -> bool:
        """ë…¹ìŒ ì‹œì‘"""
        try:
            self.is_recording = True
            self.recorded_frames = []
            self.audio_queue = queue.Queue()
            
            # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            self.stream = sd.InputStream(
                callback=self._audio_callback,
                channels=self.channels,
                samplerate=self.sample_rate,
                blocksize=self.chunk_size,
                dtype=AUDIO_FORMAT
            )
            self.stream.start()
            
            # ë…¹ìŒ ìŠ¤ë ˆë“œ ì‹œì‘
            self.recording_thread = threading.Thread(target=self._recording_worker)
            self.recording_thread.start()
            
            return True
            
        except Exception as e:
            self.is_recording = False
            return False
    
    def _recording_worker(self):
        """ë…¹ìŒ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.is_recording:
            try:
                # íƒ€ì„ì•„ì›ƒìœ¼ë¡œ íì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                audio_chunk = self.audio_queue.get(timeout=0.1)
                self.recorded_frames.append(audio_chunk)
            except queue.Empty:
                continue
    
    def stop_recording(self) -> Optional[str]:
        """ë…¹ìŒ ì¤‘ì§€ ë° íŒŒì¼ ì €ì¥"""
        if not self.is_recording:
            return None
            
        self.is_recording = False
        
        # ìŠ¤íŠ¸ë¦¼ ì •ì§€
        if hasattr(self, 'stream'):
            self.stream.stop()
            self.stream.close()
        
        # ë…¹ìŒ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if hasattr(self, 'recording_thread'):
            self.recording_thread.join(timeout=2.0)
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if not self.recorded_frames:
            return None
        
        # ì˜¤ë””ì˜¤ ë°ì´í„° ê²°í•©
        audio_data = np.concatenate(self.recorded_frames, axis=0)
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"recording_{timestamp}.wav"
        filepath = os.path.join(TEMP_AUDIO_DIR, filename)
        
        try:
            sf.write(filepath, audio_data, self.sample_rate)
            return filepath
        except Exception as e:
            return None


class STTProcessor:
    """AssemblyAIë¥¼ ì‚¬ìš©í•œ Speech-to-Text ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None):
        # API í‚¤ ì„¤ì •
        self.api_key = api_key or ASSEMBLYAI_API_KEY or os.getenv("ASSEMBLYAI_API_KEY")
        if not self.api_key:
            raise ValueError("AssemblyAI API key is required")
        
        # AssemblyAI ì„¤ì •
        aai.settings.api_key = self.api_key
        
        # ì˜¤ë””ì˜¤ ë ˆì½”ë” ì´ˆê¸°í™”
        self.audio_recorder = AudioRecorder()
    
    def start_recording(self) -> Dict[str, Any]:
        """ë…¹ìŒ ì‹œì‘"""
        success = self.audio_recorder.start_recording()
        return {
            "status": "recording" if success else "error",
            "message": "ë…¹ìŒì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤." if success else "ë…¹ìŒ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat()
        }
    
    def stop_recording(self) -> Dict[str, Any]:
        """ë…¹ìŒ ì¤‘ì§€"""
        audio_file = self.audio_recorder.stop_recording()
        
        if not audio_file:
            return {
                "status": "error",
                "message": "ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì—†ê±°ë‚˜ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "timestamp": datetime.now().isoformat()
            }
        
        return {
            "status": "stopped",
            "message": "ë…¹ìŒì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "audio_file": audio_file,
            "timestamp": datetime.now().isoformat()
        }
    
    def transcribe_audio(self, audio_file: str) -> Dict[str, Any]:
        """AssemblyAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        
        if not os.path.exists(audio_file):
            return {
                "status": "error",
                "message": f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}",
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            # AssemblyAI ì „ì‚¬ ì„¤ì • + í™”ì ë¶„ë¦¬ ê°•í™”
            config = aai.TranscriptionConfig(
                speech_model=getattr(aai.SpeechModel, ASSEMBLYAI_SPEECH_MODEL, aai.SpeechModel.best),
                language_code=ASSEMBLYAI_LANGUAGE,
                punctuate=ASSEMBLYAI_PUNCTUATE,
                format_text=ASSEMBLYAI_FORMAT_TEXT,
                disfluencies=ASSEMBLYAI_DISFLUENCIES,
                speaker_labels=ASSEMBLYAI_SPEAKER_LABELS,
                language_detection=ASSEMBLYAI_LANGUAGE_DETECTION,
                # í™”ì ë¶„ë¦¬ ê°•í™” ì„¤ì •
                speakers_expected=ASSEMBLYAI_SPEAKERS_EXPECTED  # ì˜ˆìƒ í™”ì ìˆ˜ ì§€ì •
            )
            
            # íŠ¹ì • ë‹¨ì–´ ì¸ì‹ ê°•í™” ì„¤ì •
            if ASSEMBLYAI_WORD_BOOST:
                config.word_boost = ASSEMBLYAI_WORD_BOOST
                config.boost_param = ASSEMBLYAI_BOOST_PARAM
            
            transcriber = aai.Transcriber(config=config)
            
            # ì „ì‚¬ ì‹œì‘
            transcript = transcriber.transcribe(audio_file)
            
            # ì „ì‚¬ ìƒíƒœ í™•ì¸
            while transcript.status not in [aai.TranscriptStatus.completed, aai.TranscriptStatus.error]:
                time.sleep(5)
            
            if transcript.status == aai.TranscriptStatus.error:
                return {
                    "status": "error",
                    "message": f"ì „ì‚¬ ì‹¤íŒ¨: {transcript.error}",
                    "audio_file": audio_file,
                    "timestamp": datetime.now().isoformat()
                }
            
            # ê²°ê³¼ êµ¬ì„± - í•µì‹¬ ë°ì´í„°ë§Œ ë°˜í™˜
            result = {
                "status": "success",
                "full_text": transcript.text,
                "timestamp": datetime.now().isoformat()
            }
            
            # í™”ì ë¶„ë¦¬ ê²°ê³¼ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if hasattr(transcript, 'utterances') and transcript.utterances:
                result["utterances"] = []
                for utterance in transcript.utterances:
                    result["utterances"].append({
                        "speaker": utterance.speaker,
                        "text": utterance.text,
                        "start": utterance.start / 1000,  # ms to seconds
                        "end": utterance.end / 1000
                    })
                
                # í™”ì IDë¥¼ ìˆ«ìë¡œ ë³€ê²½ (A, B â†’ 1, 2)
                result["utterances"] = self._convert_speaker_ids_to_numbers(result["utterances"])
            
            # ê²°ê³¼ ì €ì¥
            self._save_transcription_result(result)
            
            return result
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"ì „ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "audio_file": audio_file,
                "timestamp": datetime.now().isoformat()
            }
    
    def _save_transcription_result(self, result: Dict[str, Any]):
        """ì „ì‚¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            import json
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            json_file = os.path.join(OUTPUT_DIR, f"transcription_{timestamp}.json")
            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ JSON ê²°ê³¼ ì €ì¥: {json_file}")
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë„ ì €ì¥
            txt_file = os.path.join(OUTPUT_DIR, f"transcription_{timestamp}.txt")
            with open(txt_file, "w", encoding="utf-8") as f:
                f.write(f"# ì „ì‚¬ ê²°ê³¼\n")
                f.write(f"ì¼ì‹œ: {result['timestamp']}\n\n")
                f.write(f"## ì „ì²´ í…ìŠ¤íŠ¸\n\n")
                f.write(result['full_text'] or "ì „ì‚¬ ë‚´ìš© ì—†ìŒ")
                f.write("\n\n")
                
                # í™”ìë³„ ë°œì–¸
                if result.get('utterances'):
                    f.write("## í™”ìë³„ ë°œì–¸\n\n")
                    for utterance in result['utterances']:
                        f.write(f"**ì°¸ì„ì {utterance['speaker']}ë²ˆ** ({utterance['start']:.1f}s-{utterance['end']:.1f}s)\n")
                        f.write(f"{utterance['text']}\n\n")
                
            
            print(f"ğŸ’¾ í…ìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {txt_file}")
            
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    
    def _convert_speaker_ids_to_numbers(self, utterances: list) -> list:
        """í™”ì IDë¥¼ A, B, Cì—ì„œ 1, 2, 3ìœ¼ë¡œ ë³€ê²½"""
        if not utterances:
            return utterances
        
        # ê¸°ì¡´ í™”ì IDë“¤ì„ ìˆ˜ì§‘í•˜ê³  ì •ë ¬
        unique_speakers = sorted(list(set(u["speaker"] for u in utterances)))
        
        # í™”ì ë§¤í•‘ ìƒì„± (A â†’ 1, B â†’ 2, C â†’ 3 ë“±)
        speaker_mapping = {}
        for i, speaker in enumerate(unique_speakers):
            speaker_mapping[speaker] = str(i + 1)
        
        # ëª¨ë“  ë°œì–¸ì˜ í™”ì ID ë³€ê²½
        converted_utterances = []
        for utterance in utterances:
            converted_utterance = utterance.copy()
            converted_utterance["speaker"] = speaker_mapping[utterance["speaker"]]
            converted_utterances.append(converted_utterance)
        
        return converted_utterances