import assemblyai as aai
import os
import time
from datetime import datetime
from typing import Optional, Dict, Any

# Import config settings
from src.config.config import (
    ASSEMBLYAI_API_KEY,
    ASSEMBLYAI_SPEECH_MODEL,
    ASSEMBLYAI_LANGUAGE,
    ASSEMBLYAI_PUNCTUATE,
    ASSEMBLYAI_FORMAT_TEXT,
    ASSEMBLYAI_DISFLUENCIES,
    ASSEMBLYAI_SPEAKER_LABELS,
    ASSEMBLYAI_LANGUAGE_DETECTION,
    ASSEMBLYAI_WORD_BOOST,
    ASSEMBLYAI_BOOST_PARAM,
    ASSEMBLYAI_SPEAKERS_EXPECTED,
    OUTPUT_DIR
)


class STTProcessor:
    """AssemblyAIë¥¼ ì‚¬ìš©í•œ Speech-to-Text ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: Optional[str] = None):
        # API í‚¤ ì„¤ì •
        self.api_key = api_key or ASSEMBLYAI_API_KEY or os.getenv("ASSEMBLYAI_API_KEY")
        if not self.api_key:
            raise ValueError("AssemblyAI API key is required")
        
        # AssemblyAI ì„¤ì •
        aai.settings.api_key = self.api_key
    
    def transcribe_audio(self, audio_file: str) -> Dict[str, Any]:
        """AssemblyAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        
        if not os.path.exists(audio_file):
            return {
                "status": "error",
                "message": f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}",
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            # AssemblyAI ì „ì‚¬ ì„¤ì • + í™”ì ë¶„ë¦¬ ê°•í™”
            config = aai.TranscriptionConfig(
                speech_model=getattr(aai.SpeechModel, ASSEMBLYAI_SPEECH_MODEL, aai.SpeechModel.best),
                language_code=ASSEMBLYAI_LANGUAGE,
                punctuate=ASSEMBLYAI_PUNCTUATE,
                format_text=ASSEMBLYAI_FORMAT_TEXT,
                disfluencies=ASSEMBLYAI_DISFLUENCIES,
                speaker_labels=ASSEMBLYAI_SPEAKER_LABELS,
                language_detection=ASSEMBLYAI_LANGUAGE_DETECTION,
                # í™”ì ë¶„ë¦¬ ê°•í™” ì„¤ì •
                speakers_expected=ASSEMBLYAI_SPEAKERS_EXPECTED  # ì˜ˆìƒ í™”ì ìˆ˜ ì§€ì •
            )
            
            # íŠ¹ì • ë‹¨ì–´ ì¸ì‹ ê°•í™” ì„¤ì •
            if ASSEMBLYAI_WORD_BOOST:
                config.word_boost = ASSEMBLYAI_WORD_BOOST
                config.boost_param = ASSEMBLYAI_BOOST_PARAM
            
            transcriber = aai.Transcriber(config=config)
            
            # ì „ì‚¬ ì‹œì‘
            transcript = transcriber.transcribe(audio_file)
            
            # ì „ì‚¬ ìƒíƒœ í™•ì¸
            while transcript.status not in [aai.TranscriptStatus.completed, aai.TranscriptStatus.error]:
                time.sleep(5)
            
            if transcript.status == aai.TranscriptStatus.error:
                return {
                    "status": "error",
                    "message": f"ì „ì‚¬ ì‹¤íŒ¨: {transcript.error}",
                    "audio_file": audio_file,
                    "timestamp": datetime.now().isoformat()
                }
            
            # ê²°ê³¼ êµ¬ì„± - í•µì‹¬ ë°ì´í„°ë§Œ ë°˜í™˜
            result = {
                "status": "success",
                "full_text": transcript.text,
                "timestamp": datetime.now().isoformat()
            }
            
            # í™”ì ë¶„ë¦¬ ê²°ê³¼ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            if hasattr(transcript, 'utterances') and transcript.utterances:
                result["utterances"] = []
                for utterance in transcript.utterances:
                    result["utterances"].append({
                        "speaker": utterance.speaker,
                        "text": utterance.text,
                        "start": utterance.start / 1000,  # ms to seconds
                        "end": utterance.end / 1000
                    })
                
                # í™”ì IDë¥¼ ìˆ«ìë¡œ ë³€ê²½ (A, B â†’ 1, 2)
                result["utterances"] = self._convert_speaker_ids_to_numbers(result["utterances"])
            
            # ê²°ê³¼ ì €ì¥
            self._save_transcription_result(result)
            
            return result
            
        except Exception as e:
            print(f"âŒ ì „ì‚¬ ì˜¤ë¥˜: {e}")
            return {
                "status": "error",
                "message": f"ì „ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "audio_file": audio_file,
                "timestamp": datetime.now().isoformat()
            }
    
    def _save_transcription_result(self, result: Dict[str, Any]):
        """ì „ì‚¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            import json
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            json_file = os.path.join(OUTPUT_DIR, f"transcription_{timestamp}.json")
            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ JSON ê²°ê³¼ ì €ì¥: {json_file}")
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œë„ ì €ì¥
            txt_file = os.path.join(OUTPUT_DIR, f"transcription_{timestamp}.txt")
            with open(txt_file, "w", encoding="utf-8") as f:
                f.write(f"# ì „ì‚¬ ê²°ê³¼\n")
                f.write(f"ì¼ì‹œ: {result['timestamp']}\n\n")
                f.write(f"## ì „ì²´ í…ìŠ¤íŠ¸\n\n")
                f.write(result['full_text'] or "ì „ì‚¬ ë‚´ìš© ì—†ìŒ")
                f.write("\n\n")
                
                # í™”ìë³„ ë°œì–¸
                if result.get('utterances'):
                    f.write("## í™”ìë³„ ë°œì–¸\n\n")
                    for utterance in result['utterances']:
                        f.write(f"**ì°¸ì„ì {utterance['speaker']}ë²ˆ** ({utterance['start']:.1f}s-{utterance['end']:.1f}s)\n")
                        f.write(f"{utterance['text']}\n\n")
                
            
            print(f"ğŸ’¾ í…ìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {txt_file}")
            
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    
    def _convert_speaker_ids_to_numbers(self, utterances: list) -> list:
        """í™”ì IDë¥¼ A, B, Cì—ì„œ 1, 2, 3ìœ¼ë¡œ ë³€ê²½"""
        if not utterances:
            return utterances
        
        # ê¸°ì¡´ í™”ì IDë“¤ì„ ìˆ˜ì§‘í•˜ê³  ì •ë ¬
        unique_speakers = sorted(list(set(u["speaker"] for u in utterances)))
        
        # í™”ì ë§¤í•‘ ìƒì„± (A â†’ 1, B â†’ 2, C â†’ 3 ë“±)
        speaker_mapping = {}
        for i, speaker in enumerate(unique_speakers):
            speaker_mapping[speaker] = str(i + 1)
        
        # ëª¨ë“  ë°œì–¸ì˜ í™”ì ID ë³€ê²½
        converted_utterances = []
        for utterance in utterances:
            converted_utterance = utterance.copy()
            converted_utterance["speaker"] = speaker_mapping[utterance["speaker"]]
            converted_utterances.append(converted_utterance)
        
        return converted_utterances