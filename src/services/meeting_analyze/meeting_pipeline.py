from typing import Dict, Any
from langgraph.graph import StateGraph, END
import assemblyai as aai
from supabase import Client
import json
import logging
import time
from datetime import datetime

from src.utils.model import MeetingAnalyzer, SpeechTranscriber
from src.utils.stt_schemas import MeetingPipelineState, MeetingAnalysis
from src.utils.stt_utils import wait_for_transcript, process_transcript
from src.prompts.stt_generation.meeting_analysis_prompts import SYSTEM_PROMPT, USER_PROMPT
from langchain.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("meeting_pipeline")

# ì„±ëŠ¥ ë¡œê¹… ì„í¬íŠ¸
from src.utils.performance_logging import (
    time_node_execution, 
    generate_performance_report,
    SimpleTokenCallback
)

@time_node_execution("retrieve")
def retrieve_from_supabase(state: MeetingPipelineState) -> MeetingPipelineState:
    """Supabaseì—ì„œ íŒŒì¼ ì¡°íšŒ ë° URL ìƒì„±"""
    logger.info(f"ğŸ” Supabase íŒŒì¼ ì¡°íšŒ ì‹œì‘: {state['file_id']}")
    
    try:
        state["status"] = "retrieving_file"
        
        # supabase_client ê°€ì ¸ì˜¤ê¸° (í•¨ìˆ˜ ì†ì„±ìœ¼ë¡œ ì „ë‹¬ë¨)
        supabase = getattr(retrieve_from_supabase, '_supabase_client', None)
        if not supabase:
            raise ValueError("Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        bucket_name = state["bucket_name"]
        file_id = state["file_id"]
        
        # ì¬ê·€ì  íŒŒì¼ ê²€ìƒ‰
        def search_files(path: str = ""):
            try:
                files = supabase.storage.from_(bucket_name).list(path)
                found = []
                
                for file in files:
                    file_path = f"{path}/{file['name']}" if path else file['name']
                    
                    if file.get('id') is not None or '.' in file['name']:
                        if (file['name'] == file_id or 
                            file_path == file_id or 
                            file_id in file['name']):
                            found.append({**file, "full_path": file_path})
                    else:
                        try:
                            sub_found = search_files(file_path)
                            found.extend(sub_found)
                        except:
                            pass
                return found
            except:
                return []
        
        found_files = search_files()
        if not found_files:
            raise ValueError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
        
        file_info = found_files[0]
        file_path = file_info.get('full_path', file_info['name'])
        file_url = supabase.storage.from_(bucket_name).get_public_url(file_path)
        
        # state ì—…ë°ì´íŠ¸
        state["file_url"] = file_url
        state["file_path"] = file_path
        
        logger.info(f"âœ… íŒŒì¼ ì¡°íšŒ ì™„ë£Œ: {file_path}")
        
    except Exception as e:
        error_msg = f"Supabase íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        state["errors"].append(error_msg)
        state["status"] = "failed"
    
    return state


@time_node_execution("transcribe")
def process_with_assemblyai(state: MeetingPipelineState) -> MeetingPipelineState:
    logger.info("STT ì²˜ë¦¬ ì‹œì‘")
    
    try:
        state["status"] = "transcribing"
        
        if not state.get("file_url"):
            raise ValueError("íŒŒì¼ URLì´ ì—†ìŠµë‹ˆë‹¤")
        
        # AssemblyAI ì„¤ì • ë° ì „ì‚¬ ì‹œì‘
        speech_transcriber = SpeechTranscriber()
        transcriber = aai.Transcriber(config=speech_transcriber.config)
        
        logger.info(f"STT ì‹œì‘ - íŒŒì¼ URL: {state['file_url']}")
        transcript = transcriber.transcribe(state["file_url"])
        
        # ì „ì‚¬ ìƒíƒœ í™•ì¸ ë° ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ê´€ë ¨)
        transcript = wait_for_transcript(transcriber, transcript)
        
        # transcript ì²˜ë¦¬ (ë°œí™”ì‹œê°„ ê³„ì‚° í›„ í¬ë§·íŒ…)
        processed_data = process_transcript(transcript)
        
        # state ì—…ë°ì´íŠ¸
        state["transcript"] = processed_data["transcript_dict"]
        state["speaker_stats_percent"] = processed_data["speaker_stats_percent"]
        
        logger.info("âœ… STT ì²˜ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        error_msg = f"STT ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        state["errors"].append(error_msg)
        state["status"] = "failed"
    
    return state


@time_node_execution("analyze")
def analyze_with_llm(state: MeetingPipelineState) -> MeetingPipelineState:
    """LLMìœ¼ë¡œ íšŒì˜ ë¶„ì„"""
    logger.info("ğŸ¤– LLM ë¶„ì„ ì‹œì‘")
    
    try:
        state["status"] = "analyzing"
        
        if not state.get("transcript") or not state["transcript"].get("utterances"):
            raise ValueError("ì „ì‚¬ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. STT ì²˜ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # analyzerì—ì„œ LLM ê°€ì ¸ì˜¤ê¸°
        analyzer = analyze_with_llm._analyzer if hasattr(analyze_with_llm, '_analyzer') else None
        if not analyzer:
            raise ValueError("ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ì´ë¯¸ ê³„ì‚°ëœ í™”ì í†µê³„ ì‚¬ìš©
        simplified_stats = state.get("speaker_stats_percent", {})
        
        # í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì¤€ë¹„
        user_prompt_template = PromptTemplate(
            input_variables=["meeting_datetime", "transcript", "speaker_stats", "participants", "qa_pairs"],
            template=USER_PROMPT
        )
        
        # JSON ë¬¸ìì—´ ë³€í™˜
        speaker_stats_json = json.dumps(simplified_stats, ensure_ascii=False) if simplified_stats else "{}"
        qa_pairs_json = json.dumps(state.get("qa_data"), ensure_ascii=False) if state.get("qa_data") else "[]"
        participants_json = json.dumps(state.get("participants_info"), ensure_ascii=False) if state.get("participants_info") else "{}"
        
        # í”„ë¡¬í”„íŠ¸ ì²´ì¸ êµ¬ì„±
        prompt = ChatPromptTemplate.from_messages([
            ("system", SYSTEM_PROMPT),
            ("human", user_prompt_template.template)
        ])
        
        # transcriptì—ì„œ utterances ì§ì ‘ ì‚¬ìš© (ì´ë¯¸ í¬ë§·ë¨)
        transcript_for_llm = state.get("transcript", {}).get("utterances", [])
        
        # ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
        chain = prompt | analyzer.llm.with_structured_output(MeetingAnalysis)
        
        input_data = {
            "meeting_datetime": state.get("meeting_datetime", "ë‚ ì§œ/ì‹œê°„ ì •ë³´ ì—†ìŒ"),
            "transcript": transcript_for_llm,
            "speaker_stats": speaker_stats_json,
            "participants": participants_json,
            "qa_pairs": qa_pairs_json
        }
        
        # í† í° ì¶”ì ì„ ìœ„í•œ ì½œë°± ì„¤ì •
        token_callback = SimpleTokenCallback(state)
        
        # LLM í˜¸ì¶œ (with_structured_output ì‚¬ìš©í•˜ë©´ì„œ ì½œë°±ìœ¼ë¡œ í† í° ì¶”ì )
        result = chain.invoke(input_data, config={"callbacks": [token_callback]})
        
        if result is None:
            raise ValueError("1:1 íšŒì˜ ë¶„ì„ ì‹¤íŒ¨")
        
        # LLM ì‘ë‹µ ìƒì„¸ ë¡œê¹…
        logger.info(f"LLM ì‘ë‹µ íƒ€ì…: {type(result)}")
        if hasattr(result, 'detailed_discussion'):
            logger.info(f"detailed_discussion ê¸¸ì´: {len(result.detailed_discussion) if result.detailed_discussion else 0}")
            logger.info(f"detailed_discussion ë§ˆì§€ë§‰ 100ì: {result.detailed_discussion[-100:] if result.detailed_discussion else 'N/A'}")
        
        # Pydantic ê°ì²´ë¥¼ ì§ì ‘ Dictë¡œ ë³€í™˜ (JSON ë³€í™˜ ë¶ˆí•„ìš”)
        state["analysis_result"] = result.model_dump()
        state["status"] = "completed"
        
        logger.info("âœ… LLM ë¶„ì„ ì™„ë£Œ")
        
    except Exception as e:
        error_msg = f"LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        state["errors"].append(error_msg)
        state["status"] = "failed"
    
    return state


# =============================================================================
# Pipeline í´ë˜ìŠ¤
# =============================================================================

class MeetingPipeline:
    """1on1 ë¯¸íŒ… ë¶„ì„ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, supabase_client: Client, analyzer: MeetingAnalyzer):
        """
        Args:
            supabase_client: Supabase í´ë¼ì´ì–¸íŠ¸
            analyzer: íšŒì˜ ë¶„ì„ê¸°
        """
        self.supabase = supabase_client
        self.analyzer = analyzer
        self.workflow = self._build_graph()
        logger.info("MeetingPipeline ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _build_graph(self) -> Any:
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        workflow = StateGraph(MeetingPipelineState)
        
        # supabase_clientì™€ analyzerë¥¼ ë…¸ë“œ í•¨ìˆ˜ì— ë°”ì¸ë”©
        retrieve_from_supabase._supabase_client = self.supabase
        analyze_with_llm._analyzer = self.analyzer
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("retrieve", retrieve_from_supabase)
        workflow.add_node("transcribe", process_with_assemblyai)
        workflow.add_node("analyze", analyze_with_llm)
        
        # ì—£ì§€ ì—°ê²°
        workflow.set_entry_point("retrieve")
        workflow.add_edge("retrieve", "transcribe")
        workflow.add_edge("transcribe", "analyze")
        workflow.add_edge("analyze", END)
        
        return workflow.compile()
    
    async def run(self, file_id: str, **kwargs) -> Dict:
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info(f"ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘: {file_id}")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì • (íŒŒì¼ ì¡°íšŒëŠ” retrieve ë…¸ë“œì—ì„œ ì²˜ë¦¬)
        bucket_name = kwargs.get("bucket_name", "audio-recordings")
        
        initial_state: MeetingPipelineState = {
            "file_id": file_id,
            "bucket_name": bucket_name,
            "qa_data": kwargs.get("qa_data"),
            "participants_info": kwargs.get("participants_info"),
            "meeting_datetime": kwargs.get("meeting_datetime"),
            "file_url": None,  # retrieve ë…¸ë“œì—ì„œ ì„¤ì •
            "file_path": None,  # retrieve ë…¸ë“œì—ì„œ ì„¤ì •
            "transcript": None,
            "speaker_stats_percent": None,
            "analysis_result": None,
            "errors": [],
            "status": "pending"
        }
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = await self.workflow.ainvoke(initial_state)
        
        # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ ê²½ìš° ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± (ë¹„ìš© ê³„ì‚° í¬í•¨)
        if result.get("status") == "completed":
            generate_performance_report(result)
        
        logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ: {result['status']}")
        
        return result