from typing import Dict, Any
from langgraph.graph import StateGraph, END
import assemblyai as aai
from supabase import Client
import json
import logging
import time
from datetime import datetime

from src.utils.model import MeetingAnalyzer, SpeechTranscriber
from src.utils.stt_schemas import MeetingPipelineState, MeetingAnalysis
from src.prompts.stt_generation.meeting_analysis_prompts import SYSTEM_PROMPT, USER_PROMPT
from langchain.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger("meeting_pipeline")

# ì„±ëŠ¥ ë¡œê¹… ì„í¬íŠ¸
from src.utils.performance_logging import (
    time_node_execution, 
    generate_performance_report,
    SimpleTokenCallback
)

@time_node_execution("retrieve")
def retrieve_from_supabase(state: MeetingPipelineState) -> MeetingPipelineState:
    """Supabaseì—ì„œ íŒŒì¼ ì¡°íšŒ ë° URL ìƒì„±"""
    logger.info(f"ğŸ” Supabase íŒŒì¼ ì¡°íšŒ ì‹œì‘: {state['file_id']}")
    
    try:
        state["status"] = "retrieving_file"
        
        # supabase_client ê°€ì ¸ì˜¤ê¸° (í•¨ìˆ˜ ì†ì„±ìœ¼ë¡œ ì „ë‹¬ë¨)
        supabase = getattr(retrieve_from_supabase, '_supabase_client', None)
        if not supabase:
            raise ValueError("Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        bucket_name = state["bucket_name"]
        file_id = state["file_id"]
        
        # ì¬ê·€ì  íŒŒì¼ ê²€ìƒ‰
        def search_files(path: str = ""):
            try:
                files = supabase.storage.from_(bucket_name).list(path)
                found = []
                
                for file in files:
                    file_path = f"{path}/{file['name']}" if path else file['name']
                    
                    if file.get('id') is not None or '.' in file['name']:
                        if (file['name'] == file_id or 
                            file_path == file_id or 
                            file_id in file['name']):
                            found.append({**file, "full_path": file_path})
                    else:
                        try:
                            sub_found = search_files(file_path)
                            found.extend(sub_found)
                        except:
                            pass
                return found
            except:
                return []
        
        found_files = search_files()
        if not found_files:
            raise ValueError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_id}")
        
        file_info = found_files[0]
        file_path = file_info.get('full_path', file_info['name'])
        file_url = supabase.storage.from_(bucket_name).get_public_url(file_path)
        
        # state ì—…ë°ì´íŠ¸
        state["file_url"] = file_url
        state["file_path"] = file_path
        state["file_metadata"] = file_info
        
        logger.info(f"âœ… íŒŒì¼ ì¡°íšŒ ì™„ë£Œ: {file_path}")
        
    except Exception as e:
        error_msg = f"Supabase íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        state["errors"].append(error_msg)
        state["status"] = "failed"
    
    return state


@time_node_execution("transcribe")
def process_with_assemblyai(state: MeetingPipelineState) -> MeetingPipelineState:
    """AssemblyAIë¡œ STT ì²˜ë¦¬"""
    logger.info("ğŸ™ï¸ STT ì²˜ë¦¬ ì‹œì‘")
    
    try:
        state["status"] = "transcribing"
        
        if not state.get("file_url"):
            raise ValueError("íŒŒì¼ URLì´ ì—†ìŠµë‹ˆë‹¤")
        
        # AssemblyAI ì„¤ì • ë° STT ì²˜ë¦¬ (timeout ì—°ì¥)
        speech_transcriber = SpeechTranscriber()
        transcriber = aai.Transcriber(config=speech_transcriber.config)
        
        logger.info(f"ğŸ™ï¸ STT ì‹œì‘ - íŒŒì¼ URL: {state['file_url']}")
        
        # í´ë§ ë°©ì‹ìœ¼ë¡œ ì „ì‚¬ ì²˜ë¦¬ (timeout ì¦ê°€)
        transcript = transcriber.transcribe(state["file_url"])
        
        # ì „ì‚¬ ìƒíƒœ í™•ì¸ ë° ëŒ€ê¸°
        import time
        max_wait_time = 900  # 15ë¶„ timeout
        check_interval = 10   # 10ì´ˆë§ˆë‹¤ í™•ì¸
        elapsed_time = 0
        
        while transcript.status in [aai.TranscriptStatus.processing, aai.TranscriptStatus.queued]:
            if elapsed_time >= max_wait_time:
                raise TimeoutError(f"STT ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ ({max_wait_time}ì´ˆ)")
            
            logger.info(f"ğŸ”„ STT ì²˜ë¦¬ ì¤‘... ({elapsed_time}ì´ˆ ê²½ê³¼)")
            time.sleep(check_interval)
            elapsed_time += check_interval
            transcript = transcriber.get_transcript(transcript.id)
        
        if transcript.status == aai.TranscriptStatus.error:
            raise Exception(f"STT ì²˜ë¦¬ ì‹¤íŒ¨: {transcript.error}")
        
        # í™”ì í†µê³„ ê³„ì‚° (ì›ë³¸ transcript ì‚¬ìš©)
        speaker_stats = {}
        if transcript.utterances:
            for utterance in transcript.utterances:
                speaker = utterance.speaker or 'Unknown'
                if speaker not in speaker_stats:
                    speaker_stats[speaker] = {'word_count': 0, 'duration': 0}
                speaker_stats[speaker]['word_count'] += len(utterance.text.split()) if utterance.text else 0
                speaker_stats[speaker]['duration'] += (utterance.end or 0) - (utterance.start or 0)
        
        transcript_dict = {
            "utterances": [
                {
                    "speaker": utterance.speaker,
                    "text": utterance.text
                }
                for utterance in transcript.utterances
            ] if transcript.utterances else [],
            "metadata": {
                "file_id": state["file_id"],
                "processed_at": datetime.now().isoformat(),
                "total_duration": transcript.audio_duration
            }
        }
        
        state["transcript"] = transcript_dict
        state["speaker_stats"] = speaker_stats
        
        logger.info("âœ… STT ì²˜ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        error_msg = f"STT ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        state["errors"].append(error_msg)
        state["status"] = "failed"
    
    return state


@time_node_execution("analyze")
def analyze_with_llm(state: MeetingPipelineState) -> MeetingPipelineState:
    """LLMìœ¼ë¡œ íšŒì˜ ë¶„ì„"""
    logger.info("ğŸ¤– LLM ë¶„ì„ ì‹œì‘")
    
    try:
        state["status"] = "analyzing"
        
        if not state.get("transcript") or not state["transcript"].get("utterances"):
            raise ValueError("ì „ì‚¬ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. STT ì²˜ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # analyzerì—ì„œ LLM ê°€ì ¸ì˜¤ê¸°
        analyzer = analyze_with_llm._analyzer if hasattr(analyze_with_llm, '_analyzer') else None
        if not analyzer:
            raise ValueError("ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # í™”ì í†µê³„ ê°„ì†Œí™” (ë°œì–¸ ë¹„ìœ¨ ê³„ì‚°)
        simplified_stats = {}
        speaker_stats = state.get("speaker_stats", {})
        if speaker_stats:
            total_words = sum(stats.get('word_count', 0) for stats in speaker_stats.values())
            for speaker_name, stats in speaker_stats.items():
                word_count = stats.get('word_count', 0)
                percentage = round((word_count / total_words) * 100, 1) if total_words > 0 else 0
                simplified_stats[speaker_name] = percentage
        
        # í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì¤€ë¹„
        user_prompt_template = PromptTemplate(
            input_variables=["transcript", "speaker_stats", "participants", "qa_pairs"],
            template=USER_PROMPT
        )
        
        # JSON ë¬¸ìì—´ ë³€í™˜
        speaker_stats_json = json.dumps(simplified_stats, ensure_ascii=False) if simplified_stats else "{}"
        qa_pairs_json = json.dumps(state.get("qa_data"), ensure_ascii=False) if state.get("qa_data") else "[]"
        participants_json = json.dumps(state.get("participants_info"), ensure_ascii=False) if state.get("participants_info") else "{}"
        
        # í”„ë¡¬í”„íŠ¸ ì²´ì¸ êµ¬ì„±
        prompt = ChatPromptTemplate.from_messages([
            ("system", SYSTEM_PROMPT),
            ("human", user_prompt_template.template)
        ])
        
        # LLMì— í•„ìš”í•œ transcript ë°ì´í„°ë§Œ ì¶”ì¶œ
        transcript_for_llm = [
            {
                "speaker": utterance["speaker"],
                "text": utterance["text"]
            }
            for utterance in state["transcript"].get("utterances", [])
        ]
        
        # ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
        chain = prompt | analyzer.llm.with_structured_output(MeetingAnalysis)
        
        input_data = {
            "transcript": transcript_for_llm,
            "speaker_stats": speaker_stats_json,
            "participants": participants_json,
            "qa_pairs": qa_pairs_json
        }
        
        # í† í° ì¶”ì ì„ ìœ„í•œ ì½œë°± ì„¤ì •
        token_callback = SimpleTokenCallback(state)
        
        # LLM í˜¸ì¶œ (with_structured_output ì‚¬ìš©í•˜ë©´ì„œ ì½œë°±ìœ¼ë¡œ í† í° ì¶”ì )
        result = chain.invoke(input_data, config={"callbacks": [token_callback]})
        
        if result is None:
            raise ValueError("1:1 íšŒì˜ ë¶„ì„ ì‹¤íŒ¨")
        
        # LLM ì‘ë‹µ ìƒì„¸ ë¡œê¹…
        logger.info(f"LLM ì‘ë‹µ íƒ€ì…: {type(result)}")
        if hasattr(result, 'detailed_discussion'):
            logger.info(f"detailed_discussion ê¸¸ì´: {len(result.detailed_discussion) if result.detailed_discussion else 0}")
            logger.info(f"detailed_discussion ë§ˆì§€ë§‰ 100ì: {result.detailed_discussion[-100:] if result.detailed_discussion else 'N/A'}")
        
        # Pydantic ê°ì²´ë¥¼ ì§ì ‘ Dictë¡œ ë³€í™˜ (JSON ë³€í™˜ ë¶ˆí•„ìš”)
        state["analysis_result"] = result.model_dump()
        state["status"] = "completed"
        
        logger.info("âœ… LLM ë¶„ì„ ì™„ë£Œ")
        
    except Exception as e:
        error_msg = f"LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        logger.error(error_msg)
        state["errors"].append(error_msg)
        state["status"] = "failed"
    
    return state


# =============================================================================
# Pipeline í´ë˜ìŠ¤
# =============================================================================

class MeetingPipeline:
    """1on1 ë¯¸íŒ… ë¶„ì„ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, supabase_client: Client, analyzer: MeetingAnalyzer):
        """
        Args:
            supabase_client: Supabase í´ë¼ì´ì–¸íŠ¸
            analyzer: íšŒì˜ ë¶„ì„ê¸°
        """
        self.supabase = supabase_client
        self.analyzer = analyzer
        self.workflow = self._build_graph()
        logger.info("MeetingPipeline ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _build_graph(self) -> Any:
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        workflow = StateGraph(MeetingPipelineState)
        
        # supabase_clientì™€ analyzerë¥¼ ë…¸ë“œ í•¨ìˆ˜ì— ë°”ì¸ë”©
        retrieve_from_supabase._supabase_client = self.supabase
        analyze_with_llm._analyzer = self.analyzer
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("retrieve", retrieve_from_supabase)
        workflow.add_node("transcribe", process_with_assemblyai)
        workflow.add_node("analyze", analyze_with_llm)
        
        # ì—£ì§€ ì—°ê²°
        workflow.set_entry_point("retrieve")
        workflow.add_edge("retrieve", "transcribe")
        workflow.add_edge("transcribe", "analyze")
        workflow.add_edge("analyze", END)
        
        return workflow.compile()
    
    async def run(self, file_id: str, **kwargs) -> Dict:
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info(f"ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘: {file_id}")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì • (íŒŒì¼ ì¡°íšŒëŠ” retrieve ë…¸ë“œì—ì„œ ì²˜ë¦¬)
        bucket_name = kwargs.get("bucket_name", "audio-recordings")
        
        initial_state: MeetingPipelineState = {
            "file_id": file_id,
            "bucket_name": bucket_name,
            "qa_data": kwargs.get("qa_data"),
            "participants_info": kwargs.get("participants_info"),
            "meeting_datetime": kwargs.get("meeting_datetime"),
            "file_url": None,  # retrieve ë…¸ë“œì—ì„œ ì„¤ì •
            "file_path": None,  # retrieve ë…¸ë“œì—ì„œ ì„¤ì •
            "file_metadata": None,  # retrieve ë…¸ë“œì—ì„œ ì„¤ì •
            "transcript": None,
            "speaker_stats": None,
            "analysis_result": None,
            "errors": [],
            "status": "pending"
        }
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result = await self.workflow.ainvoke(initial_state)
        
        # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œëœ ê²½ìš° ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± (ë¹„ìš© ê³„ì‚° í¬í•¨)
        if result.get("status") == "completed":
            generate_performance_report(result)
        
        logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ: {result['status']}")
        
        return result